{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4G3T7fdE4S2"
      },
      "source": [
        "nikita"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o67v-CWwF3Q6",
        "outputId": "20784d81-cc61-45b7-e37f-1c766b22ff5b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "%matplotlib notebook\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import sklearn.model_selection\n",
        "import sklearn.preprocessing as preproc\n",
        "from sklearn.feature_extraction import text\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pickle\n",
        "import warnings\n",
        "import gdown\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQmnPU0oF6H3",
        "outputId": "502b9907-62aa-4338-ed6d-29a1d8c2cfdf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wF_i-hjgcy3DIKzudYDd3FPsGm8HDDXx\n",
            "To: /content/dataset.csv\n",
            "100%|██████████| 113M/113M [00:01<00:00, 59.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "url = \"https://drive.google.com/file/d/1wF_i-hjgcy3DIKzudYDd3FPsGm8HDDXx/view?usp=sharing\"\n",
        "file_id = url.split(\"/\")[-2]\n",
        "download_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "output_file = \"dataset.csv\"\n",
        "gdown.download(download_url, output_file, quiet=False)\n",
        "df = pd.read_csv(output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yzphS6bBk5O",
        "outputId": "e3f18315-2a92-4fce-9bd5-06566ed615fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(200000, 18)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6f1nW8cZ_rse"
      },
      "outputs": [],
      "source": [
        "training_data, test_data = sklearn.model_selection.train_test_split(df, test_size = 0.2, random_state=42)\n",
        "\n",
        "bow_transform = CountVectorizer(tokenizer=lambda doc: doc, ngram_range=(3,3), lowercase=False)\n",
        "\n",
        "X_tr_bow = bow_transform.fit_transform(training_data['comment_text'])\n",
        "X_te_bow = bow_transform.transform(test_data['comment_text'])\n",
        "y_tr = training_data['target']\n",
        "y_te = test_data['target']\n",
        "\n",
        "tfidf_transform = text.TfidfTransformer(norm=None)\n",
        "\n",
        "X_tr_tfidf = tfidf_transform.fit_transform(X_tr_bow)\n",
        "X_te_tfidf = tfidf_transform.transform(X_te_bow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pI2kSnOD4rEK"
      },
      "outputs": [],
      "source": [
        "y_tr = (y_tr > 0).astype(int)\n",
        "y_te = (y_te > 0).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nZ4Wt4lFBzD"
      },
      "outputs": [],
      "source": [
        "# from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
        "# from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# def simple_logistic_classify(X_tr, y_tr, X_test, y_test, description, _C=1.0):\n",
        "#     model = LogisticRegression().fit(X_tr, y_tr)\n",
        "#     y_pred = model.predict(X_test)\n",
        "#     score = accuracy_score(y_test, y_pred)\n",
        "\n",
        "#     accuracy_tfidf = accuracy_score(y_test, y_pred)\n",
        "#     print(\"Accuracy (TF-IDF):\", accuracy_tfidf)\n",
        "#     print(classification_report(y_test, y_pred))\n",
        "#     return model\n",
        "\n",
        "# model_bow = simple_logistic_classify(X_tr_bow, y_tr, X_te_bow, y_te, 'BOW')\n",
        "# model_tfidf = simple_logistic_classify(X_tr_tfidf, y_tr, X_te_tfidf, y_te, 'TF-IDF')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpeYRcuiLdg9",
        "outputId": "897cec76-5da8-4f6b-e7ae-90b9a8b8c17f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameter (C) found: {'C': 0.1}\n",
            "Accuracy : 0.81485\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.77      0.76     15042\n",
            "           1       0.86      0.84      0.85     24958\n",
            "\n",
            "    accuracy                           0.81     40000\n",
            "   macro avg       0.80      0.81      0.80     40000\n",
            "weighted avg       0.82      0.81      0.82     40000\n",
            "\n",
            "Best hyperparameter (C) found: {'C': 0.01}\n",
            "Accuracy : 0.8251\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.80      0.77     15042\n",
            "           1       0.87      0.84      0.86     24958\n",
            "\n",
            "    accuracy                           0.83     40000\n",
            "   macro avg       0.81      0.82      0.82     40000\n",
            "weighted avg       0.83      0.83      0.83     40000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "def simple_logistic_classify(X_tr, y_tr, X_test, y_test, description, _C=1.0):\n",
        "    # Define the logistic regression model\n",
        "    model = LogisticRegression(C=_C)\n",
        "\n",
        "    # Define the parameter grid for grid search\n",
        "    param_grid = {'C': [0.01, 0.1, 1]}\n",
        "\n",
        "    # Create the GridSearchCV object\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "    # Fit the grid search to the data\n",
        "    grid_search.fit(X_tr, y_tr)\n",
        "\n",
        "    # Get the best model from the grid search\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    # Predict on the test set using the best model\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    # Print the accuracy and classification report\n",
        "    accuracy_tfidf = accuracy_score(y_test, y_pred)\n",
        "    print(\"Best hyperparameter (C) found:\", grid_search.best_params_)\n",
        "    print(\"Accuracy :\", accuracy_tfidf)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    return best_model\n",
        "\n",
        "# Apply grid search for finding the best C for BOW\n",
        "model_bow = simple_logistic_classify(X_tr_bow, y_tr, X_te_bow, y_te, 'BOW')\n",
        "\n",
        "# Apply grid search for finding the best C for TF-IDF\n",
        "model_tfidf = simple_logistic_classify(X_tr_tfidf, y_tr, X_te_tfidf, y_te, 'TF-IDF')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}