{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUKI3Fa66LgD",
        "outputId": "ba5fb49c-69f9-4747-e7c2-c6fafb762685"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-gETJqZ4bZLE28ax8gbs-WX46OLWsY4F\n",
            "To: /content/my_file.ext\n",
            "100%|██████████| 816M/816M [00:07<00:00, 111MB/s]\n"
          ]
        }
      ],
      "source": [
        "import gdown\n",
        "import pandas as pd\n",
        "\n",
        "file_url = \"https://drive.google.com/uc?id=1-gETJqZ4bZLE28ax8gbs-WX46OLWsY4F\"\n",
        "output_file_path = \"/content/my_file.ext\"\n",
        "gdown.download(file_url, output_file_path, quiet=False)\n",
        "database = pd.read_csv(output_file_path)\n",
        "df = database"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XM1z4Eih6RZp",
        "outputId": "f077a3ea-3a66-4af3-c229-80b5c66bdfd1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1804874, 45)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "toxic_comments = df[df['target'] >= 0.5]\n",
        "non_toxic_comments = df[df['target'] < 0.5]\n",
        "num_rows_per_class = 100000\n",
        "\n",
        "most_toxic_comments = toxic_comments.nlargest(num_rows_per_class, 'target')\n",
        "sampled_toxic = toxic_comments.sample(n=num_rows_per_class - len(most_toxic_comments), random_state=42)\n",
        "sampled_non_toxic = non_toxic_comments.sample(n=num_rows_per_class, random_state=42)\n",
        "final_df = pd.concat([sampled_toxic, most_toxic_comments, sampled_non_toxic])\n",
        "\n",
        "final_df = final_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "print(\"Final DataFrame shape:\", final_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPWAqT5i6UaB",
        "outputId": "a1d3125e-26aa-40f9-ff30-558b33450de7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final DataFrame shape: (200000, 45)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop = ['asian', 'atheist', 'bisexual', 'black', 'buddhist', 'christian', 'female',\n",
        "                   'heterosexual', 'hindu', 'homosexual_gay_or_lesbian', 'intellectual_or_learning_disability',\n",
        "                   'jewish', 'latino', 'male', 'muslim', 'other_disability', 'other_gender', 'other_race_or_ethnicity',\n",
        "                   'other_religion', 'other_sexual_orientation', 'physical_disability', 'psychiatric_or_mental_illness',\n",
        "                   'transgender', 'white', \"created_date\",\t\"publication_id\", \"article_id\", \"parent_id\"]\n",
        "final_df = final_df.drop(columns=columns_to_drop, axis=1)\n",
        "final_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg6F1GZi6anZ",
        "outputId": "360523a3-b810-4761-fb00-51a49a1d69cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200000, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df[\"comment_text\"] = final_df[\"comment_text\"].str.lower()\n",
        "url_pattern = r\"https?://\\S+|www\\.\\S+\"\n",
        "url2 = r'https?:\\/\\/.*[\\r\\n]*'\n",
        "url3 = r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]'\n",
        "index_has_url = final_df[\"comment_text\"].str.contains(url2)\n",
        "text_has_url = final_df.loc[index_has_url, \"comment_text\"]\n",
        "import re\n",
        "sample = text_has_url.iloc[14]\n",
        "print(f\"Sample:\\n {sample}\\n\")\n",
        "print(f\"Remove URL:\\n {re.sub(url_pattern, '', sample)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "681H9fs_6bC2",
        "outputId": "f94352cd-3101-4482-e9af-94b913b7a418"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample:\n",
            " *sigh*  i'm thinking that is about 1.9 billion roubles too much to spend on that ridiculous \"sport\".  it is like an awful mashup of a 1980s aerobics workout together with a low-rent figure skating competition, accompanied by some painfully bad music that shouldn't be allowed anywhere near the name \"rock 'n' roll\":\n",
            "https://www.youtube.com/watch?v=l4j5zwl_xre\n",
            "\n",
            "Remove URL:\n",
            " *sigh*  i'm thinking that is about 1.9 billion roubles too much to spend on that ridiculous \"sport\".  it is like an awful mashup of a 1980s aerobics workout together with a low-rent figure skating competition, accompanied by some painfully bad music that shouldn't be allowed anywhere near the name \"rock 'n' roll\":\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(final_df):\n",
        "    contractions = {\n",
        "        \"ain't\": \"am not, is not, are not, has not, have not\",\n",
        "        \"aren't\": \"are not\",\n",
        "        \"can't\": \"cannot\",\n",
        "        \"could've\": \"could have\",\n",
        "        \"couldn't\": \"could not\",\n",
        "        \"didn't\": \"did not\",\n",
        "        \"doesn't\": \"does not\",\n",
        "        \"don't\": \"do not\",\n",
        "        \"gonna\": \"going to\",\n",
        "        \"gotta\": \"got to, have to\",\n",
        "        \"hadn't\": \"had not\",\n",
        "        \"hasn't\": \"has not\",\n",
        "        \"he'd\": \"he had, he would\",\n",
        "        \"he'll\": \"he will\",\n",
        "        \"here's\": \"here is\",\n",
        "        \"how'd\": \"how did\",\n",
        "        \"how's\": \"how is\",\n",
        "        \"I'd\": \"I had, I would\",\n",
        "        \"I'll\": \"I will\",\n",
        "        \"I'm\": \"I am\",\n",
        "        \"I've\": \"I have\",\n",
        "        \"it's\": \"it is\",\n",
        "        \"let's\": \"let us\",\n",
        "        \"ma'am\": \"madam\",\n",
        "        \"might've\": \"might have\",\n",
        "        \"mightn't\": \"might not\",\n",
        "        \"must've\": \"must have\",\n",
        "        \"mustn't\": \"must not\",\n",
        "        \"my\": \"mine\",\n",
        "        \"needn't\": \"need not\",\n",
        "        \"'o clock\": \"of the clock\",\n",
        "        \"o'er\": \"over\",\n",
        "        \"o's\": \"of the\",\n",
        "        \"oughtn't\": \"ought not\",\n",
        "        \"shan't\": \"shall not\",\n",
        "        \"she'd\": \"she had, she would\",\n",
        "        \"she'll\": \"she will\",\n",
        "        \"she's\": \"she is\",\n",
        "        \"should've\": \"should have\",\n",
        "        \"shouldn't\": \"should not\",\n",
        "        \"somethin'\": \"something\",\n",
        "        \"that's\": \"that is\",\n",
        "        \"they'd\": \"they had, they would\",\n",
        "        \"they'll\": \"they will\",\n",
        "        \"they're\": \"they are\",\n",
        "        \"this's\": \"this is\",\n",
        "        \"those's\": \"those are\",\n",
        "        \"'tis\": \"it is\",\n",
        "        \"twas\": \"it was\",\n",
        "        \"wanna\": \"want to\",\n",
        "        \"we'd\": \"we had, we would\",\n",
        "        \"we'll\": \"we will\",\n",
        "        \"we're\": \"we are\",\n",
        "        \"what're\": \"what are\",\n",
        "        \"what's\": \"what is\",\n",
        "        \"when's\": \"when is\",\n",
        "        \"where's\": \"where is\",\n",
        "        \"who's\": \"who is\",\n",
        "        \"would've\": \"would have\",\n",
        "        \"wouldn't\": \"would not\",\n",
        "        \"you'd\": \"you had, you would\",\n",
        "        \"you'll\": \"you will\",\n",
        "        \"you're\": \"you are\",\n",
        "    }\n",
        "\n",
        "    for contraction, expanded in contractions.items():\n",
        "        final_df[\"comment_text\"] = final_df[\"comment_text\"].str.replace(rf'\\b{contraction}\\b', expanded)\n",
        "        final_df[\"comment_text\"] = final_df[\"comment_text\"].str.lower()\n",
        "        final_df[\"comment_text\"] = final_df[\"comment_text\"].str.replace(r\"https?://\\S+|www\\.\\S+\", \" \")\n",
        "        final_df[\"comment_text\"] = final_df[\"comment_text\"].str.replace(r'https?:\\/\\/.*[\\r\\n]*', \" \")\n",
        "        final_df[\"comment_text\"] = final_df[\"comment_text\"].str.replace(r'\\<a href', \" \")\n",
        "        final_df[\"comment_text\"] = final_df[\"comment_text\"].str.replace(r'&amp;', \" \")\n",
        "        final_df[\"comment_text\"] = final_df[\"comment_text\"].str.replace(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', \" \")\n",
        "        final_df[\"comment_text\"] = final_df[\"comment_text\"].str.replace(r'<br />', \" \")\n",
        "        final_df[\"comment_text\"] = final_df[\"comment_text\"].str.replace(r'\\'', \" \")\n",
        "        final_df[\"comment_text\"] = final_df[\"comment_text\"].str.replace(r\"'\", \" \")\n",
        "    return final_df\n",
        "final_df = preprocess(final_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqKx0dvD6eIL",
        "outputId": "de11da3c-e468-4c5a-f5c9-441bc42e5d5c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-a680e37aaf54>:69: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  final_df[\"comment_text\"] = final_df[\"comment_text\"].str.replace(rf'\\b{contraction}\\b', expanded)\n",
            "<ipython-input-6-a680e37aaf54>:71: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  final_df[\"comment_text\"] = final_df[\"comment_text\"].str.replace(r\"https?://\\S+|www\\.\\S+\", \" \")\n",
            "<ipython-input-6-a680e37aaf54>:72: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  final_df[\"comment_text\"] = final_df[\"comment_text\"].str.replace(r'https?:\\/\\/.*[\\r\\n]*', \" \")\n",
            "<ipython-input-6-a680e37aaf54>:73: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  final_df[\"comment_text\"] = final_df[\"comment_text\"].str.replace(r'\\<a href', \" \")\n",
            "<ipython-input-6-a680e37aaf54>:75: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  final_df[\"comment_text\"] = final_df[\"comment_text\"].str.replace(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', \" \")\n",
            "<ipython-input-6-a680e37aaf54>:77: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  final_df[\"comment_text\"] = final_df[\"comment_text\"].str.replace(r'\\'', \" \")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "final_df['comment_text'] = final_df['comment_text'].apply(remove_stopwords)\n",
        "\n",
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    return text.translate(translator)\n",
        "final_df['comment_text'] = final_df['comment_text'].apply(remove_punctuation)\n",
        "\n",
        "\n",
        "def tokenize_text(text):\n",
        "    return word_tokenize(text)\n",
        "final_df['comment_text'] = final_df['comment_text'].apply(tokenize_text)\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def stem_text(tokens):\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
        "    return stemmed_tokens\n",
        "final_df['stemmed_text'] = final_df['comment_text'].apply(stem_text)\n",
        "# print(final_df[['id', 'comment_text', 'stemmed_text']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RUQvXnq6f8_",
        "outputId": "c5e8dea9-c823-4bf7-f26f-b37d0adc10ce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Koa1fwLTHN2Z",
        "outputId": "81ef2c43-8d21-46c9-f124-2777d1de6c6c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200000, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.to_csv('preprocessed_database_200000_0.5.csv', index=False)"
      ],
      "metadata": {
        "id": "t_jiRLN26h52"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "total_comments = len(final_df)\n",
        "toxic_comments = len(final_df[final_df['target'] >= 0.5])\n",
        "\n",
        "percentage_toxic = (toxic_comments / total_comments) * 100\n",
        "percentage_non_toxic = 100 - percentage_toxic\n",
        "\n",
        "print(f\"Percentage of toxic comments: {percentage_toxic:.2f}%\")\n",
        "print(f\"Percentage of non-toxic comments: {percentage_non_toxic:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtPPTi9m6jjv",
        "outputId": "4f6389d9-cb79-4406-9813-0ac23d4f75f5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of toxic comments: 50.00%\n",
            "Percentage of non-toxic comments: 50.00%\n"
          ]
        }
      ]
    }
  ]
}